<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Kafka Notes | Xenojoshua</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://xenojoshua.com/js/jquery.min.js"></script>
  <script src="https://xenojoshua.com/js/bootstrap.min.js"></script>
  <script src="https://xenojoshua.com/js/header.js"></script>
  <script src="https://xenojoshua.com/js/toc.js"></script>
  <link href="https://xenojoshua.com//2019/04/kafka-note/" rel="canonical" />
  <link href="https://xenojoshua.com/css/bootstrap.min.css" rel="stylesheet">
  <link href="https://xenojoshua.com/css/theme.css" rel="stylesheet">
  <link href="https://xenojoshua.com/css/syntax.css" rel="stylesheet">
  <link href="https://xenojoshua.com/css/font-awesome/css/font-awesome.min.css" rel="stylesheet">
  <link href="https://xenojoshua.com/favicon.ico?" type="image/x-icon" rel="shortcut icon">
  <style>
    /* Enhance table style */
    table {
      border: 2px solid #4F7849;
      background-color: #EEEEEE;
      width: 100%;
      text-align: center;
      border-collapse: collapse;
    }
    table td, table.comicGreen th {
      border: 1px solid #4F7849;
      padding: 3px 5px;
    }
    table tbody td {
      font-size: 14px;
      color: #4F7849;
    }
    table tr:nth-child(even) {
      background: #CEE0CC;
    }
    table thead {
      background: #4F7849;
      border-bottom: 1px solid #444444;
    }
    table thead th {
      font-size: 16px;
      font-weight: bold;
      color: #FFFFFF;
      text-align: center;
      border-left: 2px solid #D0E4F5;
      padding: 3px 5px;
    }
    table thead th:first-child {
      border-left: none;
    }
    table tfoot td {
      font-size: 21px;
    }

    /* Enhance pre style */
    pre {
      color: #FFFFFF;
      background-color: #000000;
      border-color: #000000;
    }

    /* Image bg color white while dark background */
    img {
      background-color: #FFFFFF;
    }

    /* Keep gist style clean */
    .gist table tr:nth-child(even) {
      background: #FFFFFF;
    }
    .gist td, th {
      border: none;
    }
  </style>
</head>

<body>

  
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-11349149-4']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


  

 <script type="text/javascript">
   var host = "xenojoshua.com";
   if ((host == window.location.host) && (window.location.protocol != "https:"))
     window.location.protocol = "https";
 </script>
 <script type="text/javascript">
  WebFontConfig = {
    google: {
      families: ['Ubuntu::latin']
    }
  };
  (function() {
    var wf = document.createElement('script');
    wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
      '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
    wf.type = 'text/javascript';
    wf.async = 'true';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(wf, s);
  })();
</script>

  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="https://xenojoshua.com/">Xenojoshua</a>
      </div>
      <div class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
          <li><a href="https://xenojoshua.com/">/home</a></li>
          <li><a href="https://xenojoshua.com/archive/">/archive</a></li>
          <li><a href="https://xenojoshua.com/categories/">/categories</a></li>
          <li><a href="https://xenojoshua.com/tags/">/tags</a></li>
          <li><a href="https://xenojoshua.com/feed.xml" target="_blank">/rss</a></li>
          <li><a href="https://xenojoshua.com/about/">/about</a></li>
        </ul>
      </div>
    </div>
  </nav>


<div class="wrapper">
  <div class="content">
    <div class="container container-center">
      <div class="row">
        <div class="col-md-8">
          <div class="article">
            <div class="well">
              <h1><a href="https://xenojoshua.com/2019/04/kafka-note/">Kafka Notes</a></h1>
              <div class="post-meta">
                <div class="post-time">
                  <i class="fa fa-calendar"></i>
                  <time>29 Apr 2019</time>
                </div>
                <ul>
                  
                    <li><a href="https://xenojoshua.com/tag/Kafka">Kafka</a></li>
                  
                    <li><a href="https://xenojoshua.com/tag/MessageQueue">MessageQueue</a></li>
                  
                    <li><a href="https://xenojoshua.com/tag/Keynote">Keynote</a></li>
                  
                </ul>
              </div>
              <div class="post-content">
                <h4>Table of Contents</h4>
<ul id="markdown-toc">
  <li><a href="#1-前言" id="markdown-toc-1-前言">1. 前言</a></li>
  <li><a href="#2-消息队列" id="markdown-toc-2-消息队列">2. 消息队列</a></li>
  <li><a href="#3-消息队列选型比较" id="markdown-toc-3-消息队列选型比较">3. 消息队列选型比较</a>    <ul>
      <li><a href="#31-apache-pulsar" id="markdown-toc-31-apache-pulsar">3.1 Apache Pulsar</a></li>
    </ul>
  </li>
  <li><a href="#4-kafka架构" id="markdown-toc-4-kafka架构">4. Kafka架构</a>    <ul>
      <li><a href="#41-概念" id="markdown-toc-41-概念">4.1 概念</a></li>
      <li><a href="#ID_CLUSTER" id="markdown-toc-ID_CLUSTER">4.2 集群</a></li>
      <li><a href="#43-分布式痛点offset" id="markdown-toc-43-分布式痛点offset">4.3 分布式痛点（offset）</a></li>
      <li><a href="#44-临时消费压力应急" id="markdown-toc-44-临时消费压力应急">4.4 临时消费压力应急</a></li>
    </ul>
  </li>
  <li><a href="#5-kafka监控--高可用" id="markdown-toc-5-kafka监控--高可用">5. Kafka监控 &amp; 高可用</a>    <ul>
      <li><a href="#51-监控" id="markdown-toc-51-监控">5.1 监控</a>        <ul>
          <li><a href="#511-exporter--grafana-dashboard" id="markdown-toc-511-exporter--grafana-dashboard">5.1.1 Exporter &amp; Grafana Dashboard</a></li>
          <li><a href="#512-docker实践" id="markdown-toc-512-docker实践">5.1.2 Docker实践</a></li>
        </ul>
      </li>
      <li><a href="#52-高可用" id="markdown-toc-52-高可用">5.2 高可用</a></li>
    </ul>
  </li>
  <li><a href="#6-kafka-benchmark" id="markdown-toc-6-kafka-benchmark">6. Kafka Benchmark</a>    <ul>
      <li><a href="#61-测试环境" id="markdown-toc-61-测试环境">6.1 测试环境</a></li>
      <li><a href="#62-不同场景测试" id="markdown-toc-62-不同场景测试">6.2 不同场景测试</a>        <ul>
          <li><a href="#621-场景1" id="markdown-toc-621-场景1">6.2.1 场景1</a></li>
          <li><a href="#622-场景2" id="markdown-toc-622-场景2">6.2.2 场景2</a></li>
          <li><a href="#623-场景3" id="markdown-toc-623-场景3">6.2.3 场景3</a></li>
          <li><a href="#ID_BENCHMARK_SCEN4" id="markdown-toc-ID_BENCHMARK_SCEN4">6.2.4 场景4</a></li>
          <li><a href="#625-场景5" id="markdown-toc-625-场景5">6.2.5 场景5</a></li>
          <li><a href="#626-场景6" id="markdown-toc-626-场景6">6.2.6 场景6</a></li>
        </ul>
      </li>
      <li><a href="#63-各场景测试总结" id="markdown-toc-63-各场景测试总结">6.3 各场景测试总结</a></li>
    </ul>
  </li>
  <li><a href="#7-kafka使用范例" id="markdown-toc-7-kafka使用范例">7. Kafka使用范例</a></li>
  <li><a href="#8-在docker内部署集群" id="markdown-toc-8-在docker内部署集群">8. 在Docker内部署集群</a>    <ul>
      <li><a href="#81-重要配置项" id="markdown-toc-81-重要配置项">8.1 重要配置项</a></li>
      <li><a href="#DOCKER_OUT_NET" id="markdown-toc-DOCKER_OUT_NET">8.2 对容器外应用提供服务</a></li>
      <li><a href="#83-docker-compose-scale" id="markdown-toc-83-docker-compose-scale">8.3 docker-compose scale</a></li>
      <li><a href="#84-yaml配置重用" id="markdown-toc-84-yaml配置重用">8.4 yaml配置重用</a></li>
      <li><a href="#84-相关参考" id="markdown-toc-84-相关参考">8.4 相关参考</a></li>
    </ul>
  </li>
  <li><a href="#9-写性能与安全性" id="markdown-toc-9-写性能与安全性">9. 写性能与安全性</a></li>
  <li><a href="#10-todo" id="markdown-toc-10-todo">10. TODO</a></li>
  <li><a href="#资料" id="markdown-toc-资料">资料</a>    <ul>
      <li><a href="#链接" id="markdown-toc-链接">链接</a></li>
    </ul>
  </li>
</ul>

<h1 id="1-前言">1. 前言</h1>
<p>Kafka是现在业界选择比较多的一种消息队列解决方案。我这里主要也是选Kafka作为消息队列这块需求的解决方案。下面的技术调研会先从消息队列本身开始，然后做一个横向比较，最后再聚焦到Kafka本身上。</p>

<p>调研用的Kafka版本为：</p>

<pre><code>2.2.0
</code></pre>

<p>官方文档：</p>

<ul>
  <li>官方介绍：<a href="https://kafka.apache.org/intro" target="_blank">Introduction</a></li>
  <li>官方新手入门：<a href="https://kafka.apache.org/quickstart" target="_blank">Quickstart</a></li>
  <li>官方应用场景介绍：<a href="https://kafka.apache.org/uses" target="_blank">Use cases</a></li>
  <li>官方文档：<a href="https://kafka.apache.org/documentation/" target="_blank">Documentation</a></li>
  <li>Docker Hub：<a href="https://hub.docker.com/r/wurstmeister/kafka" target="_blank">wurstmeister/kafka</a></li>
</ul>

<p>一本中文手册，版本较老，看看范例代码尚可：<a href="http://www.kubiji.cn/book/apache_kafka/APACHEKAFKAJiaoCheng/APACHEKAFKAGaiShu.html" target="_blank">Apache kafka中文手册</a>。</p>

<h1 id="2-消息队列">2. 消息队列</h1>
<p>在聊Kafka之前，其实更需要关注下消息队列本身。什么需求下需要使用消息队列、消息队列的功能点有哪些、消息队列的模式有哪些、消息队列的实现难点有哪些，等等。如果什么都不了解，那技术选型就无从谈起了，也没办法理解为什么消息队列要做好是非常困难的一件事情。展开了说，也就没办法举一反三，理解其他软件系统的设计精髓了。</p>

<p>下面会简单列举下消息队列的一系列知识点，细节内容这里就不展开了，篇幅太大。</p>

<p>消息队列的需求：</p>

<ul>
  <li>解耦</li>
  <li>最终一致性</li>
  <li>广播</li>
  <li>错峰与流控</li>
</ul>

<p>消息队列的模型：</p>

<ul>
  <li>点对点：单生产、单队列、单消费</li>
  <li>生产者消费者模型：多生产、单队列、多消费</li>
  <li>发布订阅模型：根据topic分队列，多生产、多队列、多消费</li>
</ul>

<p>消息队列的投递模式：</p>

<ul>
  <li>Push：消息队列主动推送（e.g RocketMQ可选）</li>
  <li>Pull：消费者主动抓取（e.g Kafka）</li>
</ul>

<p>消息队列的性能指标：</p>

<ul>
  <li>吞吐量（Throughput）</li>
  <li>响应时间（Latency）</li>
</ul>

<p>消息队列的投递策略：</p>

<ul>
  <li>最多一次（At most Once）：消息可能会丢，但绝不会重复传输</li>
  <li>最少一次（At least Once）：消息绝不会丢，但可能会重复传输</li>
  <li>仅有一次（Exactly Once）：每条消息肯定会被传输一次且仅传输一次</li>
</ul>

<p>消息队列的功能性：</p>

<ul>
  <li>优先级队列</li>
  <li>延迟队列</li>
  <li>死信队列</li>
  <li>重试队列</li>
  <li>消息回溯</li>
  <li>消息堆积 + 持久化</li>
  <li>消息追踪</li>
  <li>消息过滤</li>
  <li>多租户</li>
  <li>多协议支持</li>
  <li>跨语言支持</li>
  <li>流量控制</li>
  <li>可靠投递</li>
  <li>消费确认</li>
  <li>消息顺序性</li>
  <li>安全机制</li>
  <li>消息幂等性</li>
  <li>事务性消息</li>
</ul>

<p>几篇值得一读的博文：</p>

<p><a href="/2019/04/message-queue-design/" target="_blank">消息队列设计精要 - 美团点评技术团队</a></p>

<p>一篇通论形式的消息队列设计博文，讲解了一些消息队列通用的知识点，值得一读。</p>

<p><img src="/resources/2019/04/kafka-note/message-queue-01.png" alt="" target="_blank" /></p>

<p><a href="https://www.infoq.cn/article/distributed-queue-programme-model-actual-combat-optimization" target="_blank">分布式队列编程：从模型、实战到优化</a></p>

<p>本质上也是一篇对于消息队列进行设计和讲解的博文，但结合了美团公司内部的实际项目经验，对于大型系统的设计者有更好的贴近应用场景的指导作用。</p>

<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651745361&amp;idx=1&amp;sn=5f0f67484a0de4b0dd2796848ef9cc94" target="_blank">分布式队列编程优化篇</a></p>

<p>接上一篇的博文，更多讲到了性能和高级功能相关的实现以及性能的优化。</p>

<p><a href="https://www.jianshu.com/p/7a6deaba34d2" target="_blank">如何保证消息队列的高可用和幂等性以及数据丢失，顺序一致性</a></p>

<p>排版比较粗糙，但内容非常不错。以贴近项目经验的内容讲解了RabbitMQ和Kafka的：</p>

<ul>
  <li>高可用性</li>
  <li>消息幂等性</li>
  <li>消息可靠性</li>
  <li>消息顺序性</li>
  <li>消息积压场景处理</li>
</ul>

<h1 id="3-消息队列选型比较">3. 消息队列选型比较</h1>
<p>消息队列的选型一直都是比较困难的，业界现在比较主流的选择有：ActiveMQ、RabbitMQ、Kafka、RocketMQ、ZeroMQ 这几种。</p>

<p>有几篇不错的博文可以看下：</p>

<p><a href="https://www.infoq.cn/article/kafka-vs-rabbitmq" target="_blank">消息中间件选型分析：从 Kafka 与 RabbitMQ 的对比看全局</a></p>

<p>这篇时间还算比较接近<code>2018年5月2日</code>，主要是以Kafka和RabbitMQ为范例进行了消息队列选型的要点讲解。虽然讲解的时候使用了Kafka以及RabbitMQ作为范例，但实际上讲解的是通用的消息队列选型要点。结合本文上一节所讲到的消息队列的一系列知识点，应该能有更深刻的理解。</p>

<p><img src="/resources/2019/04/kafka-note/message-queue-02.jpg" alt="" target="_blank" />
<img src="/resources/2019/04/kafka-note/message-queue-03.jpg" alt="" target="_blank" />
<img src="/resources/2019/04/kafka-note/message-queue-04.jpg" alt="" target="_blank" /></p>

<p><a href="https://www.infoq.cn/article/dXJ3EYIp*WaHfmVwlMeu" target="_blank">滴滴出行基于 RocketMQ 构建企业级消息队列服务的实践</a></p>

<p>这篇时间稍微有点久，文中提到的Kafka版本还是0.8左右的（虽然文章的发布时间倒是不久之前），所以文中提到的性能指标之类的仅可作为参考。这篇文章是对Kafka和RocketMQ做的一个技术选型比较，文章中有相当多的性能指标比较，并结合滴滴公司的实际情况讲解了下消息队列系统进行替换时候所做的Migration工作，非常有借鉴价值。此外，文中还有一小节讲解了下RocketMQ使用的经验。</p>

<p><a href="https://stackoverflow.com/questions/39586635/why-is-kafka-pull-based-instead-of-push-based" target="_blank">Why is Kafka pull-based instead of push-based?</a></p>

<p>为什么Kafka消息队列使用的是Pull投递模式。</p>

<p><a href="https://medium.com/@philipfeng/modern-open-source-messaging-apache-kafka-rabbitmq-nats-pulsar-and-nsq-ca3bf7422db5" target="_blank">Modern Open Source Messaging: NATS, RabbitMQ, Apache Kafka, hmbdc, Synapse, NSQ and Pulsar</a></p>

<p>老外写的一篇，提到了不少国内较少提到的开源项目，可以作为参考。</p>

<h2 id="31-apache-pulsar">3.1 Apache Pulsar</h2>
<p>关于Kafka和后起新秀Pulsar的横向比较，可以看：</p>

<ul>
  <li><a href="https://zhuanlan.zhihu.com/p/47388267" target="_blank">比拼Kafka，大数据分析新秀Pulsar到底好在哪</a></li>
  <li><a href="https://www.slideshare.net/merlimat/high-performance-messaging-with-apache-pulsar" target="_blank">High performance messaging with Apache Pulsar</a></li>
  <li><a href="https://www.infoq.cn/article/Us*a8umKXT9LpV9hA6tF" target="_blank">选择 Pulsar 而不是 Kafka 的 7 大理由</a></li>
</ul>

<p>大略的要点：</p>

<ul>
  <li>功能性上Pulsar要比Kafka更好，且这是在不牺牲性能的前提下的，就更加难能可贵</li>
  <li>解决了Kafka单partition只能单consumer消费的问题</li>
  <li>将Broker和存储解耦，做到更好的错误恢复，在Broker宕机之后可以做到无损耗恢复</li>
  <li>存储方面的功能交付给Bookie，更细粒度的存储，更好的错误恢复和同步性能</li>
</ul>

<h1 id="4-kafka架构">4. Kafka架构</h1>
<h2 id="41-概念">4.1 概念</h2>
<p>老样子从基本的概念开始梳理：</p>

<ul>
  <li><code>broker</code>：kafka集群中的任意一台提供服务的物理服务器即被称为broker</li>
  <li><code>topic</code>：消息队列的一个队列，一般做架构的时候按需求将不同的消息分别派送到不同的管道里，而其中的任意一个管道在kafka里就是一个topic</li>
  <li><code>partition</code>：topic下的概念，任意一个topic根据启动时的设定，会分成多个partition，而每个partition会由集群安排在某一台物理机broker上，以此做到集群的横向扩展</li>
  <li><code>offset</code>：partition下的概念，topic被分为很多partition，而每个partition则都会存储消息，每个partition存储的消息都是从0开始进行标号，而这个每条消息一个的标号，即为offset；可以理解为消息在partition里的唯一id；不同的partition都是从0开始标号，因此offset只对其自身的partition生效，不可混用</li>
  <li><code>replica</code>：某个partition的完整备份（在接收写入请求时数据可能会落后于leader），用在集群的高可用服务上，同时也可以提供partition读操作的负载均衡</li>
  <li><code>producer</code>：向topic里输入消息数据的角色</li>
  <li><code>consumer</code>：从topic里消费消息数据的角色</li>
  <li><code>consumer group</code>：可扩展且具有容错性的consumer机制，多个consumer共享一个group id，组内的所有consumer一起来消费topic的所有partition；但一个partition仍旧只能由一个consumer进行消费；主要是为了解决consumer和partition配对balance的问题，将consumer做成组由集群自动进行平衡并分配到partition</li>
</ul>

<p>关于consumer group，更多的可以看：<a href="https://www.cnblogs.com/huxi2b/p/6223228.html" target="_blank">Kafka消费组(consumer group)</a>。</p>

<h2 id="ID_CLUSTER">4.2 集群</h2>
<p>一张图基本上就能说明问题：</p>

<p><img src="/resources/2019/04/kafka-note/message-queue-05.jpg" alt="" target="_blank" /></p>

<ul>
  <li>kafka集群由多台broker（物理机）组成</li>
  <li>图示中有<code>四台</code>broker</li>
  <li>每个topic会根据配置，生成固定数量的partition，均匀分配到物理机上</li>
  <li>图示中的topic被分成了<code>3个</code>partition：<code>P1_leader</code>（broker1）、<code>P2_leader</code>（broker2）、<code>P3_leader</code>（broker4）</li>
  <li>每个partition根据配置，会拥有固定数量的follower（replica），分别分配到各个物理机上</li>
  <li>图示中即：<code>P1_follower</code>（broker2、broker3）、<code>P2_follower</code>（broker3、broker4）、<code>P3_follower</code>（broker1、broker2）</li>
  <li>当有broker宕机的时候：
    <ul>
      <li>丢失的follower会由集群重新寻找节点进行备份<code>恢复</code></li>
      <li>丢失的leader会由集群自现存的follower中<code>选举</code>产生，成为新的leader</li>
    </ul>
  </li>
</ul>

<h2 id="43-分布式痛点offset">4.3 分布式痛点（offset）</h2>
<p>Kafka在分布式解决方案上也有痛点，主要是每个partition的offset问题。</p>

<p>为了性能，kafka将一个partition视作一个管道，拥有一个从0开始的offset。这样做的好处就是不再需要在每一个消息体上做metadata存放该消息是否被消费掉等信息，而是通过partition的offset来标记整个管道中的消息被消费到了哪里。消息体更简单，流程上也更简单，不会出现乱序的消费情况。但也正是因为这种设计，导致每个partition无法由多个consumer并发消费，每个partition绑定只能同时允许一个consumer消费。</p>

<p>因此，从机制上来说，kafka并不适合用来做consumer重消耗（CPU）类型的消息通道。虽然partition可以做很多，极端点来说可以做到和consumer实际需求1：1的配比，但超过适配当前需求的partition数量设置也会造成吞吐量的下降（参见：<a href="#ID_BENCHMARK_SCEN4">6.2.4 场景4</a>）。</p>

<p>consumer和partition在进行消息是否被消费掉的确认行为上，有两种方式：</p>

<ul>
  <li>自动提交：
    <ul>
      <li>设置<code>enable.auto.commit=true</code></li>
      <li>更新的频率根据参数<code>auto.commit.interval.ms</code>来定，这种方式被称为<code>at most once</code></li>
      <li>consumer fetch到消息后，partition就会更新offset，无论是否消费成功</li>
    </ul>
  </li>
  <li>手动提交：
    <ul>
      <li>设置<code>enable.auto.commit=false</code></li>
      <li>这种方式被称为<code>at least once</code></li>
      <li>consumer fetch到消息后，必须在消费成功后调用方法<code>consumer.commitSync()</code>，手动通知partition更新offset</li>
      <li>如果消费失败，则offset不会更新，此条消息会被重复消费一次</li>
    </ul>
  </li>
</ul>

<p>关于partition和consumer之间的关系，更多可以看下：</p>

<p><a href="https://stackoverflow.com/questions/45175424/how-multiple-consumer-group-consumers-work-across-partition-on-the-same-topic-in" target="_blank">How multiple consumer group consumers work across partition on the same topic in Kafka?</a></p>

<blockquote>
  <p>If you want to have more consumers than partitions and still have performance enhancement and process only each message once, then you should increase the number of partitions in the topics so that there are at least as many partitions as consumers. Often topics are created with 2 times as many partitions needed to start, just so more consumers can be added later if needed without having to repartition the topic.</p>
</blockquote>

<p><a href="https://blog.csdn.net/pursuer211/article/details/79799478" target="_blank">kafka中partition和消费者对应关系</a></p>

<blockquote>
  <p>1个partition只能被同组的一个consumer消费，同组的consumer则起到均衡效果</p>
</blockquote>

<p>以及自动提交相关：<a href="https://medium.com/@danieljameskay/understanding-the-enable-auto-commit-kafka-consumer-property-12fa0ade7b65" target="_blank">Understanding the ‘enable.auto.commit’ Kafka Consumer property</a>。</p>

<h2 id="44-临时消费压力应急">4.4 临时消费压力应急</h2>
<p>如果因某些原因，之前设计的partition分片数量不够导致能够上工的consumer数量不够，且consumer的消费速率跟不上的时候，就会发生消息堆积。如果堆积的情况比较严重的话，就需要程序介入处理。</p>

<p>思路如下：</p>

<ol>
  <li>老的partition以及老的topic肯定不能动，就算重新进行repartition整个集群重新平衡耗费的时间也是难以忍受的</li>
  <li>创建新的topic</li>
  <li>将新的topic的partition设到consumer消费速率能跟上的数量</li>
  <li>将新的consumer部署上去，消费新设置的topic和partition</li>
  <li>将老的topic以及partition上挂载的consumer全部停止</li>
  <li>在老的topic以及partition上挂载临时consumer，这批consumer不做任何逻辑处理，只是将老的topic内的消息全部读取出来，并输入到新的topic里</li>
</ol>

<p>这样老的topic里的消息就全部分发到新的topic里了，且新的topic的partition数量很高，可以挂载很多consumer处理堆积的消息。</p>

<h1 id="5-kafka监控--高可用">5. Kafka监控 &amp; 高可用</h1>
<h2 id="51-监控">5.1 监控</h2>
<p>监控方面，datadog的几篇文章非常不错，值得一读，不过版本有点老了，文章是2016年的：</p>

<ul>
  <li><a href="https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/" target="_blank">Monitoring Kafka performance metrics - P1</a></li>
  <li><a href="https://www.datadoghq.com/blog/collecting-kafka-performance-metrics/" target="_blank">Monitoring Kafka performance metrics - P2</a></li>
</ul>

<p>详细的指标列表及其含义，可以看这篇：<a href="https://docs.confluent.io/current/kafka/monitoring.html" target="_blank">Monitoring Kafka</a>。</p>

<h3 id="511-exporter--grafana-dashboard">5.1.1 Exporter &amp; Grafana Dashboard</h3>
<p>Prometheus的Exporter分为两块：</p>

<ul>
  <li>以Java为runtime的通用监控：prometheus/jmx_exporter
    <ul>
      <li>代码：<a href="https://github.com/prometheus/jmx_exporter" target="_blank">prometheus/jmx_exporter</a></li>
      <li>镜像：<a href="https://hub.docker.com/r/sscaling/jmx-prometheus-exporter" target="_blank">sscaling/jmx-prometheus-exporter</a>
        <ul>
          <li>sscaling/jmx-prometheus-exporter:0.11.0</li>
        </ul>
      </li>
      <li>Dashboard：
        <ul>
          <li><a href="https://grafana.com/dashboards/721" target="_blank">Kafka Overview</a>，这个dashboard相当老了，一直没有更新，而且仅只有6个Panel，和kafka有关的panel更只有3个，基本没什么用；但未能找到更近一点的kafka专用dashboard</li>
          <li><a href="https://grafana.com/dashboards/8563">JVM dashboard</a>，jmx通用dashboard，看上去更好点；但这个dashboard变量设置的是job，所以在设置Prometheus的时候就需要将多个kafka的数据采集到同一个job里，而不是分开</li>
          <li><a href="https://grafana.com/dashboards/7727">JMX exporter prometheus</a>，另一款jmx通用dashboard；这个dashboard是为了在k8s中使用而特化的，也不够灵活</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>列在Prometheus官方列表上的第三方Exporter：danielqsj/kafka_exporter
    <ul>
      <li>代码：<a href="https://github.com/danielqsj/kafka_exporter" target="_blank">danielqsj/kafka_exporter</a></li>
      <li>镜像：<a href="https://hub.docker.com/r/danielqsj/kafka-exporter" target="_blank">danielqsj/kafka-exporter</a>
        <ul>
          <li>danielqsj/kafka-exporter:v1.2.0</li>
        </ul>
      </li>
      <li>Dashboard：<a href="https://grafana.com/dashboards/7589" target="_blank">Kafka Exporter Overview</a></li>
      <li>该Exporter使用Golang编写，更专注于部分Kafka业务相关metrics，对于核心的Java runtime metrics仍旧需要jmx_exporter</li>
    </ul>
  </li>
</ul>

<p>此外，还有一个confluent公司的grafana dashboard配置，没找到对应的labs dashboard地址，但该配置文件本身也有参考价值：<a href="https://github.com/kubernauts/kafka-confluent-platform/blob/master/grafana-kafka-dashboard.json" target="_blank">kafka-confluent-platform/grafana-kafka-dashboard.json</a>。</p>

<p>可参考的jmx_exporter配置：</p>

<ul>
  <li><a href="https://github.com/oded-dd/prometheus-jmx-kafka" target="_blank">oded-dd/prometheus-jmx-kafka</a></li>
  <li><a href="https://github.com/Mousavi310/kafka-grafana" target="_blank">Mousavi310/kafka-grafana</a></li>
</ul>

<h3 id="512-docker实践">5.1.2 Docker实践</h3>
<p>实际运行范例参见：</p>

<ul>
  <li><a href="https://github.com/agreatfool/dist-system-practice/blob/master/golang/src/dist-system-practice/conf/dev/kafka-cluster.yaml" target="_blank">dist-system-practice/conf/dev/kafka-cluster.yaml</a></li>
  <li><a href="https://github.com/agreatfool/dist-system-practice/blob/master/golang/src/dist-system-practice/conf/dev/prometheus-cluster.yaml" target="_blank">dist-system-practice/conf/dev/prometheus-cluster.yaml</a></li>
  <li><a href="https://github.com/agreatfool/dist-system-practice/tree/master/golang/src/dist-system-practice/vendors/kafka" target="_blank">dist-system-practice/vendors/kafka/</a></li>
  <li><a href="https://github.com/agreatfool/dist-system-practice/tree/master/golang/src/dist-system-practice/vendors/prometheus/grafana/dashboards" target="_blank">dist-system-practice/vendors/prometheus/grafana/dashboards/</a></li>
</ul>

<p>Exporter方面，jmx_exporter和kafka_exporter同时使用，两者侧重不同。jmx_exporter主要用来进行JVM监控，针对java runtime自身的状态进行监控，而kafka_exporter则针对kafka运行状况进行监控（其实只要不怕麻烦自己处理dashboard，则jmx_exporter就完全足够了）。</p>

<p>jmx_exporter的部署有两种选择，一是独立的容器进行部署，好处是可观察性强，且不会对kafka容器造成影响，缺点是部署更繁杂，配置内容更多；二是修改kafka容器，添加几项配置项，就可以直接在kafka容器内启动一个java进程，进行metrics输出。这里实践使用的是第二种方法，配置修改如下：</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span></span>  <span class="l l-Scalar l-Scalar-Plain">kafka_1</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">image</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="l l-Scalar l-Scalar-Plain">volumes</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/private/tmp/jmx_prometheus_javaagent-0.9.jar:/usr/local/bin/jmx_prometheus_javaagent-0.9.jar</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/private/tmp/jmx-kafka-2_0_0.yaml:/etc/jmx-exporter/jmx-kafka-2_0_0.yaml</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="l l-Scalar l-Scalar-Plain">networks</span><span class="p p-Indicator">:</span>
      <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="l l-Scalar l-Scalar-Plain">ports</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;19092:9092&quot;</span> <span class="c1"># client port</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;17071:7071&quot;</span> <span class="c1"># jmx prometheus metrics</span>
    <span class="l l-Scalar l-Scalar-Plain">expose</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;9092&quot;</span> <span class="c1"># client port</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;9093&quot;</span> <span class="c1"># internal traffic</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;9991&quot;</span> <span class="c1"># jmx</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;7071&quot;</span> <span class="c1"># jmx prometheus metrics</span>
    <span class="l l-Scalar l-Scalar-Plain">restart</span><span class="p p-Indicator">:</span> <span class="s">&quot;always&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">logging</span><span class="p p-Indicator">:</span>
      <span class="l l-Scalar l-Scalar-Plain">&lt;&lt;</span><span class="p p-Indicator">:</span> <span class="nv">*KAFKA_LOGGING_DEFAULTS</span>
    <span class="l l-Scalar l-Scalar-Plain">environment</span><span class="p p-Indicator">:</span>
      <span class="l l-Scalar l-Scalar-Plain">...</span>
      <span class="l l-Scalar l-Scalar-Plain">JMX_PORT</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">9991</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_OPTS</span><span class="p p-Indicator">:</span> <span class="s">&quot;-javaagent:/usr/local/bin/jmx_prometheus_javaagent-0.9.jar=7071:/etc/jmx-exporter/jmx-kafka-2_0_0.yaml&quot;</span>
      <span class="l l-Scalar l-Scalar-Plain">&lt;&lt;</span><span class="p p-Indicator">:</span> <span class="nv">*KAFKA_ENV_DEFAULTS</span></code></pre></figure>

<p><code>JMX_PORT</code>告知kafka在启动的时候需要一并启动jmx，<code>KAFKA_OPTS</code>告知kafka在启动时一并需要启动jmx_exporter，而这个exporter的jar包以及配置文件则是通过bind mount放入容器内的。</p>

<p>配置文件主要来自于：<a href="https://github.com/Mousavi310/kafka-grafana/blob/master/jmx-exporter/kafka-2_0_0.yml" target="_blank">kafka-grafana/jmx-exporter/kafka-2_0_0.yml</a>。此外，因为使用通用jmx dashboard：<a href="https://grafana.com/dashboards/8563" target="_blank">JVM dashboard</a>来进行数据展示，该配置文件中也放入了部分这个dashboard要求的数据转换规则：</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span></span><span class="l l-Scalar l-Scalar-Plain">lowercaseOutputLabelNames</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>

<span class="l l-Scalar l-Scalar-Plain">rules</span><span class="p p-Indicator">:</span>
<span class="c1"># JMX common</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">pattern</span><span class="p p-Indicator">:</span> <span class="s">&#39;java.lang&lt;type=OperatingSystem&gt;&lt;&gt;(committed_virtual_memory|free_physical_memory|free_swap_space|total_physical_memory|total_swap_space)_size:&#39;</span>
  <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">os_$1_bytes</span>
  <span class="l l-Scalar l-Scalar-Plain">type</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">GAUGE</span>
  <span class="l l-Scalar l-Scalar-Plain">attrNameSnakeCase</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">pattern</span><span class="p p-Indicator">:</span> <span class="s">&#39;java.lang&lt;type=OperatingSystem&gt;&lt;&gt;((?!process_cpu_time)\w+):&#39;</span>
  <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">os_$1</span>
  <span class="l l-Scalar l-Scalar-Plain">type</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">GAUGE</span>
  <span class="l l-Scalar l-Scalar-Plain">attrNameSnakeCase</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nn">...</span></code></pre></figure>

<p>此外还有prometheus集群采集添加以及grafana dashboard导入，都是常规操作，就不多说了。</p>

<h2 id="52-高可用">5.2 高可用</h2>
<p>在之前的<a href="#ID_CLUSTER">4.2 集群</a>中，已经介绍过了Kafka的集群模式，可以看到Kafka天然就是分布式的，而且在设计之初就考虑到了集群的高可用。本文之前章节内关于集群的内容偏简单了，只介绍了大致的设计。如有需要更深入了解分布式和高可用的细节，则可以阅读唯品会的：<a href="https://www.infoq.cn/article/depth-interpretation-of-kafka-data-reliability" target="_blank">Kafka 数据可靠性深度解读</a>，这篇讲解非常透彻，基本上可以当经典来看了。</p>

<p>Kafka的高可用配置，有几个配置项控制了集群的安全程度。这里需要记住一点，整个集群越安全集群的吞吐量就越低，这是等价交换的，不可能不付出任何代价就获得数据的安全性。唯品会的文章讲解的细节非常多，但我们真正执行操作的时候可以只知其然，懂得哪几个配置项需要操作即可：</p>

<ul>
  <li>topic：
    <ul>
      <li><code>replication.factor</code>：每个partition会拥有多少个replica</li>
      <li><code>min.insync.replicas</code>：partition的leader节点要求当前在线的replica节点的数量，如果实际在线数量少于这个数值，客户端的请求会被拒绝：<code>org.apache.kafka.common.errors.NotEnoughReplicasExceptoin: Messages are rejected since there are fewer in-sync replicas than required</code></li>
    </ul>
  </li>
  <li>broker：
    <ul>
      <li><code>unclean.leader.election.enable</code>：是否允许out-of-sync replica成为leader</li>
    </ul>
  </li>
  <li>producer：
    <ul>
      <li>producer.type：消息生产者提交消息到kafka服务器的时候的模式，可选：sync或async
        <ul>
          <li><code>sync</code>拥有很好的安全性</li>
          <li><code>async</code>拥有更高的吞吐量，可以批量进行消息发送</li>
        </ul>
      </li>
      <li>request.required.acks：kafka服务器在收到消息之后何时对生产者进行完成反馈
        <ul>
          <li><code>1（默认）</code>：partition的leader节点收取完成即反馈，如果在follower同步数据之前leader宕机则数据丢失</li>
          <li><code>0</code>：producer不等待kafka服务器反馈即直接进行后续发送，拥有最高的吞吐量以及最低的安全性</li>
          <li><code>-1</code>：partition的所有节点包括了leader以及所有的follower全部都确认数据同步完成再反馈，最高的安全性以及最低的吞吐量</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>要保证数据写入到Kafka是安全的，高可靠的，需要如下配置：</p>

<ul>
  <li>topic：
    <ul>
      <li>replication.factor&gt;=3：即副本数至少是3个</li>
      <li>2&lt;=min.insync.replicas&lt;=replication.factor：要求每个partition leader的在线replica数量最少保持2个</li>
    </ul>
  </li>
  <li>broker：
    <ul>
      <li>unclean.leader.election.enable=false：不允许out-of-sync replica成为leader</li>
    </ul>
  </li>
  <li>producer：
    <ul>
      <li>request.required.acks=-1(all)：producer发送的消息请求必须让partition所有的replica都同步完毕才会返回成功</li>
      <li>producer.type=sync：producer发送的消息以同步方式发送，即在写入成功之前，producer必须等待</li>
    </ul>
  </li>
</ul>

<h1 id="6-kafka-benchmark">6. Kafka Benchmark</h1>
<p>这里的内容全部是转载自唯品会的：<a href="https://www.infoq.cn/article/depth-interpretation-of-kafka-data-reliability" target="_blank">Kafka 数据可靠性深度解读</a>。网上的资料很容易失效，因此在这里做下转载。</p>

<p>Benchmark的Kafka版本是：</p>
<pre><code>0.10.1.0
</code></pre>

<h2 id="61-测试环境">6.1 测试环境</h2>
<p>Kafka broker 用到了 4 台机器，分别为 broker[0/1/2/3] 配置如下：</p>

<ul>
  <li>CPU: 24core/2.6GHZ</li>
  <li>Memory: 62G</li>
  <li>Network: 4000Mb</li>
  <li>OS/kernel: CentOs release 6.6 (Final)</li>
  <li>Disk: 1089G</li>
  <li>Kafka 版本：0.10.1.0</li>
</ul>

<p>broker 端 JVM 参数设置：</p>

<pre><code>-Xmx8G -Xms8G -server -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC -Djava.awt.headless=true -Xloggc:/apps/service/kafka/bin/../logs/kafkaServer-gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=9999
</code></pre>

<p>客户端机器配置：</p>

<ul>
  <li>CPU: 24core/2.6GHZ</li>
  <li>Memory: 3G</li>
  <li>Network: 1000Mb</li>
  <li>OS/kernel: CentOs release 6.3 (Final)</li>
  <li>Disk: 240G</li>
</ul>

<h2 id="62-不同场景测试">6.2 不同场景测试</h2>
<h3 id="621-场景1">6.2.1 场景1</h3>
<p>测试不同的副本数、min.insync.replicas 策略以及 request.required.acks 策略（以下简称 acks 策略）对于发送速度（TPS）的影响。</p>

<p>具体配置：</p>

<ul>
  <li>一个 producer</li>
  <li>发送方式为 sync</li>
  <li>消息体大小为 1kB</li>
  <li>partition 数为 12</li>
  <li>副本数为：1/2/4</li>
  <li>min.insync.replicas 分别为 1/2/4</li>
  <li>acks 分别为 -1（all）/1/0</li>
</ul>

<p>具体测试数据如下表（min.insync.replicas 只在 acks=-1 时有效）：</p>

<p><img src="/resources/2019/04/kafka-note/message-queue-06.jpg" alt="" target="_blank" /></p>

<p>测试结果分析：</p>

<ul>
  <li>客户端的 acks 策略对发送的 TPS 有较大的影响，TPS：acks_0 &gt; acks_1 &gt; ack_-1;</li>
  <li>副本数越高，TPS 越低；副本数一致时，min.insync.replicas 不影响 TPS；</li>
  <li>acks=0/1 时，TPS 与 min.insync.replicas 参数以及副本数无关，仅受 acks 策略的影响。</li>
</ul>

<p>下面将 partition 的个数设置为 1，来进一步确认下不同的 acks 策略、不同的 min.insync.replicas 策略以及不同的副本数对于发送速度的影响，详细请看情景 2 和情景 3。</p>

<h3 id="622-场景2">6.2.2 场景2</h3>
<p>在 partition 个数固定为 1，测试不同的副本数和 min.insync.replicas 策略对发送速度的影响。</p>

<p>具体配置：</p>

<ul>
  <li>一个 producer</li>
  <li>发送方式为 sync</li>
  <li>消息体大小为 1kB</li>
  <li>producer 端 acks=-1(all)</li>
  <li>变换副本数：2/3/4</li>
  <li>min.insync.replicas 设置为：1/2/4</li>
</ul>

<p>测试结果如下：</p>

<p><img src="/resources/2019/04/kafka-note/message-queue-07.jpg" alt="" target="_blank" /></p>

<p>测试结果分析：</p>

<p>副本数越高，TPS 越低（这点与场景 1 的测试结论吻合），但是当 partition 数为 1 时差距甚微。min.insync.replicas 不影响 TPS。</p>

<h3 id="623-场景3">6.2.3 场景3</h3>
<p>在 partition 个数固定为 1，测试不同的 acks 策略和副本数对发送速度的影响。</p>

<p>具体配置：</p>

<ul>
  <li>一个 producer</li>
  <li>发送方式为 sync</li>
  <li>消息体大小为 1kB</li>
  <li>min.insync.replicas=1</li>
  <li>topic 副本数为：1/2/4</li>
  <li>acks： 0/1/-1</li>
</ul>

<p>测试结果如下：</p>

<p><img src="/resources/2019/04/kafka-note/message-queue-08.jpg" alt="" target="_blank" /></p>

<p>测试结果分析（与情景 1 一致）：</p>

<ul>
  <li>副本数越多，TPS 越低；</li>
  <li>客户端的 acks 策略对发送的 TPS 有较大的影响，TPS：acks_0 &gt; acks_1 &gt; ack_-1。</li>
</ul>

<h3 id="ID_BENCHMARK_SCEN4">6.2.4 场景4</h3>
<p>测试不同 partition 数对发送速率的影响</p>

<p>具体配置：</p>

<ul>
  <li>一个 producer</li>
  <li>消息体大小为 1KB</li>
  <li>发送方式为 sync</li>
  <li>topic 副本数为 2</li>
  <li>min.insync.replicas=2</li>
  <li>acks=-1</li>
  <li>partition 数量设置为 1/2/4/8/12</li>
</ul>

<p>测试结果：</p>

<p><img src="/resources/2019/04/kafka-note/message-queue-09.jpg" alt="" target="_blank" /></p>

<p>测试结果分析：</p>

<p>partition 的不同会影响 TPS，随着 partition 的个数的增长 TPS 会有所增长，但并不是一直成正比关系，到达一定临界值时，partition 数量的增加反而会使 TPS 略微降低。</p>

<h3 id="625-场景5">6.2.5 场景5</h3>
<p>通过将集群中部分 broker 设置成不可服务状态，测试对客户端以及消息落盘的影响。</p>

<p>具体配置：</p>

<ul>
  <li>一个 producer</li>
  <li>消息体大小 1KB</li>
  <li>发送方式为 sync</li>
  <li>topic 副本数为 4</li>
  <li>min.insync.replicas 设置为 2</li>
  <li>acks=-1</li>
  <li>retries=0/100000000</li>
  <li>partition 数为 12</li>
</ul>

<p>具体测试数据如下表：</p>

<p><img src="/resources/2019/04/kafka-note/message-queue-10.jpg" alt="" target="_blank" /></p>

<p>出错信息：</p>

<ul>
  <li>错误 1：客户端返回异常，部分数据可落盘，部分失败：org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</li>
  <li>错误 2：[WARN]internals.Sender - Got error produce response with correlation id 19369 on topic-partition default_channel_replicas_4_1-3, retrying (999999999 attempts left). Error: NETWORK_EXCEPTION</li>
  <li>错误 3： [WARN]internals.Sender - Got error produce response with correlation id 77890 on topic-partition default_channel_replicas_4_1-8, retrying (999999859 attempts left). Error: NOT_ENOUGH_REPLICAS</li>
  <li>错误 4： [WARN]internals.Sender - Got error produce response with correlation id 77705 on topic-partition default_channel_replicas_4_1-3, retrying (999999999 attempts left). Error: NOT_ENOUGH_REPLICAS_AFTER_APPEND</li>
</ul>

<p>测试结果分析：</p>

<ul>
  <li>kill 两台 broker 后，客户端可以继续发送。broker 减少后，partition 的 leader 分布在剩余的两台 broker 上，造成了 TPS 的减小；</li>
  <li>kill 三台 broker 后，客户端无法继续发送。Kafka 的自动重试功能开始起作用，当大于等于 min.insync.replicas 数量的 broker 恢复后，可以继续发送；</li>
  <li>当 retries 不为 0 时，消息有重复落盘；客户端成功返回的消息都成功落盘，异常时部分消息可以落盘。</li>
</ul>

<h3 id="626-场景6">6.2.6 场景6</h3>
<p>测试单个 producer 的发送延迟，以及端到端的延迟。</p>

<p>具体配置：</p>

<ul>
  <li>一个 producer</li>
  <li>消息体大小 1KB</li>
  <li>发送方式为 sync</li>
  <li>topic 副本数为 4</li>
  <li>min.insync.replicas 设置为 2</li>
  <li>acks=-1</li>
  <li>partition 数为 12</li>
</ul>

<p>测试数据及结果（单位为 ms）：</p>

<p><img src="/resources/2019/04/kafka-note/message-queue-11.jpg" alt="" target="_blank" /></p>

<h2 id="63-各场景测试总结">6.3 各场景测试总结</h2>

<ul>
  <li>当 acks=-1 时，Kafka 发送端的 TPS 受限于 topic 的副本数量（ISR 中），副本越多 TPS 越低；</li>
  <li>acks=0 时，TPS 最高，其次为 1，最差为 -1，即 TPS：acks_0 &gt; acks_1 &gt; ack_-1；</li>
  <li>min.insync.replicas 参数不影响 TPS；</li>
  <li>partition 的不同会影响 TPS，随着 partition 的个数的增长 TPS 会有所增长，但并不是一直成正比关系，到达一定临界值时，partition 数量的增加反而会使 TPS 略微降低；</li>
  <li>Kafka 在 acks=-1,min.insync.replicas&gt;=1 时，具有高可靠性，所有成功返回的消息都可以落盘。</li>
</ul>

<h1 id="7-kafka使用范例">7. Kafka使用范例</h1>
<p>实验使用的还是下载下来的Kafka，版本如头部申明的是<code>2.2.0</code>。范例代码可以在Github查看：<a href="https://github.com/agreatfool/dist-system-practice/tree/master/experiment/kafka" target="_blank">dist-system-practice/experiment/kafka/</a>。</p>

<h1 id="8-在docker内部署集群">8. 在Docker内部署集群</h1>
<p>一般来说部署一个以上的docker容器组成集群，可以使用bash脚本的方法，自己编写命令一个个启动，但更好的方法是使用<code>docker-compose</code>命令，读取配置文件，将整个集群按设定的模式启动起来。可运行范例可以查看：<a href="https://github.com/agreatfool/dist-system-practice/blob/master/golang/src/dist-system-practice/conf/dev/kafka-cluster.yaml" target="_blank">dist-system-practice/conf/dev/kafka-cluster.yaml</a>。</p>

<p>启动脚本：<a href="https://github.com/agreatfool/dist-system-practice/blob/master/golang/src/dist-system-practice/bash/dev/docker_kafka.sh" target="_blank">dist-system-practice/bash/dev/docker_kafka.sh</a>。</p>

<p>主要有几个点需要注意下。</p>

<h2 id="81-重要配置项">8.1 重要配置项</h2>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span></span><span class="l l-Scalar l-Scalar-Plain">services</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">kafka_1</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">image</span><span class="p p-Indicator">:</span> <span class="s">&quot;wurstmeister/kafka:2.12-2.2.0&quot;</span> <span class="c1"># 一定需要</span>
    <span class="l l-Scalar l-Scalar-Plain">hostname</span><span class="p p-Indicator">:</span> <span class="s">&quot;kafka_1&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">container_name</span><span class="p p-Indicator">:</span> <span class="s">&quot;kafka_1&quot;</span> <span class="c1"># 使用这个名字来让同network的其他服务进行访问</span>
    <span class="l l-Scalar l-Scalar-Plain">depends_on</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;zookeeper&quot;</span> <span class="c1"># 保证启动先后顺序</span>
    <span class="l l-Scalar l-Scalar-Plain">volumes</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/private/tmp/jmx_prometheus_javaagent-0.9.jar:/usr/local/bin/jmx_prometheus_javaagent-0.9.jar</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/private/tmp/jmx-kafka-2_0_0.yaml:/etc/jmx-exporter/jmx-kafka-2_0_0.yaml</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">kafka_vol_1:/tmp/kafka/data</span>
    <span class="l l-Scalar l-Scalar-Plain">networks</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;net&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">ports</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;19092:9092&quot;</span> <span class="c1"># client port # 保证非同一network的其他服务也能访问，但这么做要求每个kafka service都监听不同的端口，相互不能冲突</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;17071:7071&quot;</span> <span class="c1"># jmx prometheus metrics</span>
    <span class="l l-Scalar l-Scalar-Plain">expose</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;9092&quot;</span> <span class="c1"># client port</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;9093&quot;</span> <span class="c1"># internal traffic # kafka集群内部流量走的端口号</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;9991&quot;</span> <span class="c1"># jmx # jmx进程本身监听的地址，提供给jmx_exporter连接用</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;7071&quot;</span> <span class="c1"># jmx prometheus metrics # jmx_exporter监听的地址，提供给prometheus抓取metrics</span>
    <span class="l l-Scalar l-Scalar-Plain">restart</span><span class="p p-Indicator">:</span> <span class="s">&quot;always&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">logging</span><span class="p p-Indicator">:</span>
      <span class="l l-Scalar l-Scalar-Plain">driver</span><span class="p p-Indicator">:</span> <span class="s">&quot;json-file&quot;</span> <span class="c1"># 日志输出以json格式，容易让聚合工具使用</span>
      <span class="l l-Scalar l-Scalar-Plain">options</span><span class="p p-Indicator">:</span>
        <span class="l l-Scalar l-Scalar-Plain">max-size</span><span class="p p-Indicator">:</span> <span class="s">&quot;512m&quot;</span> <span class="c1"># 保证日志最大尺寸不会过大占用过多系统磁盘</span>
    <span class="l l-Scalar l-Scalar-Plain">environment</span><span class="p p-Indicator">:</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_LISTENERS</span><span class="p p-Indicator">:</span> <span class="s">&quot;INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092&quot;</span> <span class="c1"># kafka的实际监听地址，一般不是0.0.0.0就是容器名</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_ADVERTISED_LISTENERS</span><span class="p p-Indicator">:</span> <span class="s">&quot;INSIDE://kafka_1:9093,OUTSIDE://127.0.0.1:19092&quot;</span> <span class="c1"># kafka发布到zookeeper，让客户端获取并凭之连接kafka的地址，一定需要是客户端能访问到的地址，INSIDE部分供集群内部流量使用，OUTSIDE供客户端使用</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_LISTENER_SECURITY_PROTOCOL_MAP</span><span class="p p-Indicator">:</span> <span class="s">&quot;INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT&quot;</span> <span class="c1"># 明确内部外部的通讯协议</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_INTER_BROKER_LISTENER_NAME</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">INSIDE</span> <span class="c1"># 告诉kafka集群上面的INSIDE和OUTSIDE配置哪个才是供集群内部流量使用的，按语义一般是INSIDE</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_BROKER_ID</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span> <span class="c1"># 必须每个kafka broker单独一个，不可重复</span>
      <span class="l l-Scalar l-Scalar-Plain">JMX_PORT</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">9991</span> <span class="c1"># jmx监听的地址</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_OPTS</span><span class="p p-Indicator">:</span> <span class="s">&quot;-javaagent:/usr/local/bin/jmx_prometheus_javaagent-0.9.jar=7071:/etc/jmx-exporter/jmx-kafka-2_0_0.yaml&quot;</span> <span class="c1"># kafka在启动时一并会给予启动</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_ZOOKEEPER_CONNECT</span><span class="p p-Indicator">:</span> <span class="s">&quot;zookeeper:2181&quot;</span> <span class="c1"># 告知kafka zookeeper的地址</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_LOG_DIRS</span><span class="p p-Indicator">:</span> <span class="s">&quot;/tmp/kafka-logs&quot;</span> <span class="c1"># kafka实际的数据存放位置，推荐使用volume进行该地址的local映射</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span> <span class="c1"># kafka内部用来保存topic的offset的数据，其replication数量</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span> <span class="c1"># kafka内部用来保存transaction state log的数据，其replication数量</span>
      <span class="l l-Scalar l-Scalar-Plain">KAFKA_MIN_INSYNC_REPLICAS</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span> <span class="c1"># partition的leader节点要求当前在线的replica节点的数量</span></code></pre></figure>

<p>关于<code>LISTENER</code>相关的几个配置（用于集群访问）更多的可以看下：<a href="#DOCKER_OUT_NET">8.2 对容器外应用提供服务</a>。</p>

<p>参见：</p>

<ul>
  <li><a href="https://docs.confluent.io/current/kafka/deployment.html" target="_blank">Running Kafka in Production</a></li>
</ul>

<h2 id="DOCKER_OUT_NET">8.2 对容器外应用提供服务</h2>
<p>在docker中部署集群有一个比较大的问题就是容器内部和外部的网络访问地址是隔离的，而kafka集群部分节点的相互发现是根据配置：<code>KAFKA_ADVERTISED_LISTENERS</code>来进行通知的。</p>

<p>如果该配置内的地址填写的是<code>127.0.0.1</code>这样的回环地址或容器外的IP，那么容器内各kafka节点之间的通讯就会有问题（因为容器内各节点拿到的配置地址都是容器外的IP）。而如果将该配置内的地址都配置成docker容器的名字，那么在容器内部的流量是没问题了，但外部访问kafka服务的应用程序拿到的地址则是容器的名字，就没法访问了。</p>

<p>所以对于需要向容器外部环境的应用提供服务的情况来说，需要做好几项配置的调整（这里说的配置都是kafka的配置，不涉及到zookeeper的配置，事实上集群部署的配置中zookeeper相关的内容非常简单）：</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span></span><span class="l l-Scalar l-Scalar-Plain">KAFKA_LISTENERS</span><span class="p p-Indicator">:</span> <span class="s">&quot;INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092&quot;</span>
<span class="l l-Scalar l-Scalar-Plain">KAFKA_ADVERTISED_LISTENERS</span><span class="p p-Indicator">:</span> <span class="s">&quot;INSIDE://kafka_1:9093,OUTSIDE://127.0.0.1:19092&quot;</span>
<span class="l l-Scalar l-Scalar-Plain">KAFKA_LISTENER_SECURITY_PROTOCOL_MAP</span><span class="p p-Indicator">:</span> <span class="s">&quot;INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT&quot;</span>
<span class="l l-Scalar l-Scalar-Plain">KAFKA_INTER_BROKER_LISTENER_NAME</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">INSIDE</span></code></pre></figure>

<p>kafka的配置中，现在可以将内部流量和外部流量的监听地址分离开来，在配置<code>LISTENERS</code>相关的配置时，使用<code>,</code>将<code>INSIDE</code>和<code>OUTSIDE</code>隔离开来即可。一般来说，<code>INSIDE</code>的地址会配置成当前节点的容器名，或者就直接设置成<code>0.0.0.0</code>。而<code>OUTSIDE</code>则根据自身需求设置即可，这里的范例是给本机开发测试用，因此设置的是<code>127.0.0.1</code>。</p>

<p><code>KAFKA_INTER_BROKER_LISTENER_NAME</code>配置项则是告诉kafka，集群各broker节点之间是使用INSIDE还是OUTSIDE配置作为集群内部流量的通讯地址。此外需要注意的是，该配置的<code>INSIDE</code>和<code>OUTSIDE</code>监听的端口是<code>不可以重复</code>的，因为实际上kafka就是开了两个端口都在监听。</p>

<p>一般第一次在本地设置集群进行开发和调试的时候，这里是个大坑，非常麻烦。配置不正确就会发现kafka完全无法通讯。</p>

<h2 id="83-docker-compose-scale">8.3 docker-compose scale</h2>
<p>一般来说，kafka service的配置不适合在配置文件中只设置一份，然后使用docker-compose scale的方法进行横向扩展。</p>

<p>适用scale的场景只有完全无状态，且各个节点之间的配置完全相同的情况，而kafka各节点一般最好设置自身的<code>container_name</code>，然后在监听地址中使用正确的容器名作为地址，来进行相互通讯。</p>

<h2 id="84-yaml配置重用">8.4 yaml配置重用</h2>
<p>因为无法使用scale的缘故，必须手写大量的kafka service节点yaml配置，这倒也不算是大问题。关键的问题在于有大量重复的配置项，如果后面要修改，就很麻烦，怕漏改或者改错。</p>

<p>因此最好的方法是使用yaml的配置重用，来设置共通的配置，然后像变量一样重用。这可以参见我之前提到的范例配置文件：</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span></span><span class="l l-Scalar l-Scalar-Plain">x-kafka-environment-defaults</span><span class="p p-Indicator">:</span> <span class="nl">&amp;KAFKA_ENV_DEFAULTS</span>
  <span class="l l-Scalar l-Scalar-Plain">...</span>
  <span class="l l-Scalar l-Scalar-Plain"># 在这里放默认的配置</span>
  <span class="l l-Scalar l-Scalar-Plain">...</span>

<span class="l l-Scalar l-Scalar-Plain">services</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">kafka_1</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="l l-Scalar l-Scalar-Plain">environment</span><span class="p p-Indicator">:</span>
      <span class="l l-Scalar l-Scalar-Plain">...</span>
      <span class="l l-Scalar l-Scalar-Plain">&lt;&lt;</span><span class="p p-Indicator">:</span> <span class="nv">*KAFKA_ENV_DEFAULTS</span> <span class="c1"># 这样就把作为变量的配置全部导入到这个点上了</span></code></pre></figure>

<h2 id="84-相关参考">8.4 相关参考</h2>
<ul>
  <li><a href="https://better-coding.com/building-apache-kafka-cluster-using-docker-compose-and-virtualbox/" target="_blank">Building Apache Kafka cluster using docker-compose and VirtualBox</a></li>
  <li><a href="https://www.kaaproject.org/kafka-docker" target="_blank">Deploying a Kafka broker in a Docker container</a></li>
</ul>

<h1 id="9-写性能与安全性">9. 写性能与安全性</h1>
<p>在进行测试的过程中，发现写入的速度比较慢，基本上每次写入在kafka集群这边会耗时1秒多，完全不能接受了。之前的博文中也提到了，集群安全性和写入性能是反比的，主要有几项因素：</p>

<ul>
  <li>producer的写入模式：同步、异步
    <ul>
      <li>异步拥有最佳的性能，但安全性极差</li>
      <li>同步性能很差，但安全性有保证</li>
    </ul>
  </li>
  <li>acks写入的集群同步模式：-1完全同步、0完全不等待同步、1Leader节点同步
    <ul>
      <li>0拥有最佳性能，最低的安全性</li>
      <li>-1拥有最佳性能，但性能最低</li>
      <li>1则比较均衡</li>
    </ul>
  </li>
  <li>partition数量：acks如果为-1，则需要同步所有节点，partition数量越多则性能越低</li>
</ul>

<p>后续进行了一些研究和测试。</p>

<p>集群共3个broker，topic分片如下：</p>

<pre><code>Topic:work-topic	PartitionCount:3	ReplicationFactor:3	Configs:
	Topic: work-topic	Partition: 0	Leader: 2	Replicas: 2,0,1	Isr: 2,0,1
	Topic: work-topic	Partition: 1	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0
	Topic: work-topic	Partition: 2	Leader: 0	Replicas: 0,1,2	Isr: 0,1,2
</code></pre>

<p>查了下官方配置，<code>producer.acks</code>这个现在放在<code>3.3 Producer Configs</code>里，命名为<code>acks</code>（<a href="https://kafka.apache.org/22/documentation.html#producerconfigs" target="_blank">链接</a>）。需要注意的是，这一项配置并不是服务端的配置项，而是连接上来的客户端producer所进行的设置，是否acks根据客户端producer的要求而变动。这很反直觉，我一开始一直都以为这是服务端的配置项，没想到居然是客户端的。</p>

<p>acks在kafka-go的使用，可以查看注释：<a href="https://github.com/segmentio/kafka-go/blob/v0.2.4/writer.go#L101" target="_blank">kafka-go/writer.go</a>，默认是-1，也就是最安全但最慢的那种。</p>

<p>此外，写入模式是同步还是异步也是客户端设置，见：<a href="https://github.com/segmentio/kafka-go/blob/v0.2.4/writer.go#L105" target="_blank">kafka-go/writer.go</a>。</p>

<p>在上面提到的几项要素中，集群规模和partition数量之类都是业务要求，一般不会轻易变动，所以测试主要是实验在不同写入模式和acks情况下的性能变动。</p>

<p>测试：</p>

<pre><code>同步 -1 1秒+
同步 1  1秒+
同步 0  1秒+
异步 -1 0.2ms 几乎瞬间完成
异步 1  0.2ms 几乎瞬间完成
异步 0  0.2ms 几乎瞬间完成
</code></pre>

<p>结论：性能只在于是否将客户端设置成异步写入，acks对性能的影响微乎其微。</p>

<p>但上述的测试是在MAC本地环境进行的，有几项因素不够稳定：</p>

<ul>
  <li>kafka集群的内存很小</li>
  <li>磁盘IO和实际情况差别较大</li>
  <li>集群规模过小</li>
  <li>partition数量很少（集群和partition数量很小能够部分解释为什么acks的改动基本上不影响性能）</li>
</ul>

<p>因此上述测试的结论主要是参考价值，不能作为最终结论。如果后续需要严谨结论的话，需要在真实机器上测试，并需要开启go的profiling，观察下kafka类库中的写入到底是怎么完成的，以及kafka集群的响应情况。此外，即便是模拟集群1秒左右的同步写入速度也实在是太慢了，后续还需要深入profiling，到底这1秒做了什么（无论是kafka还是go客户端）。</p>

<h1 id="10-todo">10. TODO</h1>
<ul>
  <li>深入研究Kafka的监控Metrics</li>
  <li>Kafka集群同步写入性能较低的原因解析</li>
</ul>

<h1 id="资料">资料</h1>
<h2 id="链接">链接</h2>
<ul>
  <li><a href="http://www.kubiji.cn/book/apache_kafka/APACHEKAFKAJiaoCheng/APACHEKAFKAGaiShu.html" target="_blank">Apache kafka中文手册</a></li>
  <li><a href="https://www.infoq.cn/article/distributed-queue-programme-model-actual-combat-optimization" target="_blank">分布式队列编程：从模型、实战到优化</a></li>
  <li><a href="https://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651745361&amp;idx=1&amp;sn=5f0f67484a0de4b0dd2796848ef9cc94" target="_blank">分布式队列编程优化篇</a></li>
  <li><a href="https://www.jianshu.com/p/7a6deaba34d2" target="_blank">如何保证消息队列的高可用和幂等性以及数据丢失，顺序一致性</a></li>
  <li><a href="https://www.infoq.cn/article/kafka-vs-rabbitmq" target="_blank">消息中间件选型分析：从 Kafka 与 RabbitMQ 的对比看全局</a></li>
  <li><a href="https://www.infoq.cn/article/dXJ3EYIp*WaHfmVwlMeu" target="_blank">滴滴出行基于 RocketMQ 构建企业级消息队列服务的实践</a></li>
  <li><a href="https://stackoverflow.com/questions/39586635/why-is-kafka-pull-based-instead-of-push-based" target="_blank">Why is Kafka pull-based instead of push-based?</a></li>
  <li><a href="https://medium.com/@philipfeng/modern-open-source-messaging-apache-kafka-rabbitmq-nats-pulsar-and-nsq-ca3bf7422db5" target="_blank">Modern Open Source Messaging: NATS, RabbitMQ, Apache Kafka, hmbdc, Synapse, NSQ and Pulsar</a></li>
  <li><a href="https://www.cnblogs.com/huxi2b/p/6223228.html" target="_blank">Kafka消费组(consumer group)</a></li>
  <li><a href="https://stackoverflow.com/questions/45175424/how-multiple-consumer-group-consumers-work-across-partition-on-the-same-topic-in" target="_blank">How multiple consumer group consumers work across partition on the same topic in Kafka?</a></li>
  <li><a href="https://blog.csdn.net/pursuer211/article/details/79799478" target="_blank">kafka中partition和消费者对应关系</a></li>
  <li><a href="https://medium.com/@danieljameskay/understanding-the-enable-auto-commit-kafka-consumer-property-12fa0ade7b65" target="_blank">Understanding the ‘enable.auto.commit’ Kafka Consumer property</a></li>
  <li><a href="https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/" target="_blank">Monitoring Kafka performance metrics - P1</a></li>
  <li><a href="https://www.datadoghq.com/blog/collecting-kafka-performance-metrics/" target="_blank">Monitoring Kafka performance metrics - P2</a></li>
  <li><a href="https://github.com/danielqsj/kafka_exporter" target="_blank">danielqsj/kafka_exporter</a></li>
  <li><a href="https://docs.confluent.io/current/kafka/monitoring.html" target="_blank">Monitoring Kafka</a></li>
  <li><a href="https://www.infoq.cn/article/depth-interpretation-of-kafka-data-reliability" target="_blank">Kafka 数据可靠性深度解读</a></li>
  <li><a href="https://better-coding.com/building-apache-kafka-cluster-using-docker-compose-and-virtualbox/" target="_blank">Building Apache Kafka cluster using docker-compose and VirtualBox</a></li>
  <li><a href="https://www.kaaproject.org/kafka-docker" target="_blank">Deploying a Kafka broker in a Docker container</a></li>
  <li><a href="https://docs.confluent.io/current/kafka/deployment.html" target="_blank">Running Kafka in Production</a></li>
  <li><a href="https://zhuanlan.zhihu.com/p/47388267" target="_blank">比拼Kafka，大数据分析新秀Pulsar到底好在哪</a></li>
  <li><a href="https://www.slideshare.net/merlimat/high-performance-messaging-with-apache-pulsar" target="_blank">High performance messaging with Apache Pulsar</a></li>
  <li><a href="https://www.infoq.cn/article/Us*a8umKXT9LpV9hA6tF" target="_blank">选择 Pulsar 而不是 Kafka 的 7 大理由</a></li>
  <li><a href="https://github.com/prometheus/jmx_exporter" target="_blank">prometheus/jmx_exporter</a></li>
  <li><a href="https://hub.docker.com/r/sscaling/jmx-prometheus-exporter" target="_blank">sscaling/jmx-prometheus-exporter</a></li>
  <li><a href="https://github.com/danielqsj/kafka_exporter" target="_blank">danielqsj/kafka_exporter</a></li>
  <li><a href="https://hub.docker.com/r/danielqsj/kafka-exporter" target="_blank">danielqsj/kafka-exporter</a></li>
  <li><a href="https://github.com/oded-dd/prometheus-jmx-kafka" target="_blank">oded-dd/prometheus-jmx-kafka</a></li>
  <li><a href="https://github.com/Mousavi310/kafka-grafana" target="_blank">Mousavi310/kafka-grafana</a></li>
</ul>

<blockquote>
  <p>EOF</p>
</blockquote>

              </div>
              
              <div id="disqus_thread">
                <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
              </div>
              
            </div>
          </div>
        </div>
        <div class="col-md-4 hidden-xs">
          <div class="sidebar ">
  <h2>Recent Posts</h2>
  <ul>
    
    <li><a href="/2020/03/japanese/">日语自学笔记</a></li>
    
    <li><a href="/2019/12/wxpay/">微信支付接入</a></li>
    
    <li><a href="/2019/12/alipay/">支付宝接入</a></li>
    
    <li><a href="/2019/12/docker-registry/">Docker Registry 的简单使用</a></li>
    
    <li><a href="/2019/12/gitea-note/">Gitea简单介绍及使用</a></li>
    
  </ul>
</div>

<div class="sidebar">
  <h2>Categories</h2>
  <ul>
    
      <li><a href="/category/Linux">Linux</a></li>
    
      <li><a href="/category/Stress & Scaling">Stress & Scaling</a></li>
    
      <li><a href="/category/PHP">PHP</a></li>
    
      <li><a href="/category/IDE">IDE</a></li>
    
      <li><a href="/category/Wordpress">Wordpress</a></li>
    
      <li><a href="/category/SEO">SEO</a></li>
    
      <li><a href="/category/Version Control">Version Control</a></li>
    
      <li><a href="/category/HTML & CSS">HTML & CSS</a></li>
    
      <li><a href="/category/Trash">Trash</a></li>
    
      <li><a href="/category/Apache">Apache</a></li>
    
      <li><a href="/category/Memcache">Memcache</a></li>
    
      <li><a href="/category/Net Services">Net Services</a></li>
    
      <li><a href="/category/Java">Java</a></li>
    
      <li><a href="/category/MicroBlog">MicroBlog</a></li>
    
      <li><a href="/category/JavaScript">JavaScript</a></li>
    
      <li><a href="/category/DB">DB</a></li>
    
      <li><a href="/category/Something">Something</a></li>
    
      <li><a href="/category/Methodology & Thinking">Methodology & Thinking</a></li>
    
      <li><a href="/category/Redis">Redis</a></li>
    
      <li><a href="/category/Flash">Flash</a></li>
    
      <li><a href="/category/Thinking">Thinking</a></li>
    
      <li><a href="/category/Platform">Platform</a></li>
    
      <li><a href="/category/C _ C++">C / C++</a></li>
    
      <li><a href="/category/Dart">Dart</a></li>
    
      <li><a href="/category/Mobile">Mobile</a></li>
    
      <li><a href="/category/Video">Video</a></li>
    
      <li><a href="/category/Blog">Blog</a></li>
    
      <li><a href="/category/Politics">Politics</a></li>
    
      <li><a href="/category/V8Blog">V8Blog</a></li>
    
      <li><a href="/category/Docker">Docker</a></li>
    
      <li><a href="/category/Golang">Golang</a></li>
    
      <li><a href="/category/Career">Career</a></li>
    
      <li><a href="/category/Prometheus">Prometheus</a></li>
    
      <li><a href="/category/Grafana">Grafana</a></li>
    
      <li><a href="/category/Logging">Logging</a></li>
    
      <li><a href="/category/Jaeger">Jaeger</a></li>
    
      <li><a href="/category/Elasticsearch">Elasticsearch</a></li>
    
      <li><a href="/category/MessageQueue">MessageQueue</a></li>
    
      <li><a href="/category/Kafka">Kafka</a></li>
    
      <li><a href="/category/gRPC">gRPC</a></li>
    
      <li><a href="/category/Envoy">Envoy</a></li>
    
      <li><a href="/category/DistributedSystem">DistributedSystem</a></li>
    
      <li><a href="/category/Tor">Tor</a></li>
    
      <li><a href="/category/Node.js">Node.js</a></li>
    
      <li><a href="/category/CI">CI</a></li>
    
      <li><a href="/category/ServiceDiscovery">ServiceDiscovery</a></li>
    
      <li><a href="/category/Git">Git</a></li>
    
      <li><a href="/category/Payment">Payment</a></li>
    
      <li><a href="/category/Japanese">Japanese</a></li>
    
  </ul>
</div>

        </div>
      </div>
    </div>
    
<!-- Add Disqus comments. -->
<div id="disqus_thread"></div>
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  var disqus_shortname = "xenojoshua"; // required: replace example with your forum shortname
  var disqus_identifier = "/2019/04/kafka-note/";

  /* * * DON'T EDIT BELOW THIS LINE * * */
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  </div>
      <footer class="footer-distributed">
      <div class="container">
        <div class="footer">
          <p>Jonathan Dai &copy; 2019</p>
          <h6>Theme by <a href="https://github.com/streetturtle/jekyll-clean-dark" target="_blank">Pavel Makhov</a></h6>
          <h6>Follow me</h6>

<ul class="social-media">

  
    <li>
      <a title="agreatfool on Github" href="https://github.com/agreatfool" target="_blank"><i class="fa fa-github fa-2x"></i></a>
    </li>
  

  

  

  

  

  
    <li>
      <a title="feed.xml RSS" href="https://xenojoshua.com/feed.xml" target="_blank"><i class="fa fa-rss fa-2x"></i></a>
    </li>
  

</ul>

        </div>
      </div>
    </footer>
  </body>
</html>

</div>
